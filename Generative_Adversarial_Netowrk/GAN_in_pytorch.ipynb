{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1\n",
    "\n",
    "# ### Uncomment only one of these\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yi/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1189: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 0.2612496018409729/0.7550960779190063 G: 0.6319496035575867 (Real: [3.881776454001665, 1.3058554984265063], Fake: [0.34714002758264539, 0.013925168078822258]) \n",
      "200: D: -1.000088900582341e-12/0.1943722516298294 G: 1.7466143369674683 (Real: [3.919493629038334, 1.278808678596596], Fake: [-0.24533017694950104, 0.0012270249925156239]) \n",
      "400: D: -1.000088900582341e-12/0.10825973004102707 G: 2.294783115386963 (Real: [3.7743106368929147, 1.5686935209310764], Fake: [-0.39478518813848495, 0.017708721492327557]) \n",
      "600: D: -1.000088900582341e-12/0.05873845890164375 G: 2.8944711685180664 (Real: [3.9866126239299775, 1.2762855689696464], Fake: [-0.34019537091255186, 0.078327143105248118]) \n",
      "800: D: -1.000088900582341e-12/0.054303526878356934 G: 3.2106664180755615 (Real: [3.9703823983669282, 1.209226298433937], Fake: [-0.18055458210408687, 0.2166505761596022]) \n",
      "1000: D: 0.0009939244482666254/0.03329313173890114 G: 3.267967939376831 (Real: [4.1688681280612947, 1.1199689775010326], Fake: [0.019086868762969972, 0.40539560518369727]) \n",
      "1200: D: 0.00012219698692206293/0.17298561334609985 G: 3.191922187805176 (Real: [4.1614144122600552, 1.4415254222943819], Fake: [2.0736019521951676, 0.7526778805078419]) \n",
      "1400: D: 1.5582395792007446/0.6022223830223083 G: 1.6349343061447144 (Real: [3.943383476138115, 1.2632377736639611], Fake: [3.9751274859905243, 0.94639635151146684]) \n",
      "1600: D: 0.9955592751502991/0.7138783931732178 G: 0.4069380760192871 (Real: [4.0973564112186436, 1.2081538569082715], Fake: [4.8491497671604158, 1.2062629730985448]) \n",
      "1800: D: 0.6484591960906982/0.8514066338539124 G: 0.1761305034160614 (Real: [4.054148997664452, 1.155277466292397], Fake: [4.3411367511749264, 1.7890240019211499]) \n",
      "2000: D: 0.2613157033920288/0.4899042546749115 G: 0.8545626997947693 (Real: [3.9812360477447508, 1.4428794204532065], Fake: [5.5199758291244505, 1.0444176127525855]) \n",
      "2200: D: 0.5702680945396423/0.5064588785171509 G: 1.2711058855056763 (Real: [3.950375347137451, 1.1970569064435168], Fake: [4.6698857629299164, 1.6006614596515922]) \n",
      "2400: D: 0.5395927429199219/0.39386826753616333 G: 1.2430986166000366 (Real: [4.1127827990055081, 1.2476841410884738], Fake: [4.7848271107673641, 1.2327498201904636]) \n",
      "2600: D: 0.9103429317474365/0.49494409561157227 G: 0.8547731637954712 (Real: [4.2185098010301587, 1.1374360626241595], Fake: [4.371666142940521, 1.371369755960729]) \n",
      "2800: D: 0.6746911406517029/0.8114216327667236 G: 0.5734150409698486 (Real: [4.0965807163715366, 1.2483091919344349], Fake: [3.8431075763702394, 1.175668413559261]) \n",
      "3000: D: 0.461368590593338/0.8603490591049194 G: 0.8404313921928406 (Real: [3.9272651147842406, 1.2950119510556977], Fake: [3.5065127134323122, 1.1503744656821118]) \n",
      "3200: D: 0.6803624033927917/0.6072691082954407 G: 0.5693575143814087 (Real: [4.082258176803589, 1.2442099928898931], Fake: [3.5350941550731658, 0.98995798046503269]) \n",
      "3400: D: 0.8795457482337952/0.9119352698326111 G: 0.7569437623023987 (Real: [3.8180247884988785, 1.237088641745864], Fake: [3.9755941236019137, 1.2109076412880673]) \n",
      "3600: D: 1.0835845470428467/0.7671456336975098 G: 0.8063220977783203 (Real: [4.0286023759841916, 0.92965005277900814], Fake: [4.5396355634927748, 1.2383459979757991]) \n",
      "3800: D: 0.6826750636100769/0.5952579975128174 G: 0.5367391705513 (Real: [4.012061351239681, 1.2432513905336897], Fake: [4.8970468127727509, 0.9419480004681694]) \n",
      "4000: D: 0.5524056553840637/0.6686183214187622 G: 0.7814449667930603 (Real: [3.9555285447835922, 1.2394179820927738], Fake: [4.4031071448326111, 1.1344541242260149]) \n",
      "4200: D: 0.7118241190910339/0.7035579681396484 G: 0.6413102746009827 (Real: [4.0006918704509733, 1.1350075967402105], Fake: [3.8426016771793368, 1.1940559648769082]) \n",
      "4400: D: 0.5138850808143616/0.781010091304779 G: 0.6257195472717285 (Real: [3.8388050228357313, 1.3857107546377867], Fake: [3.6900656294822691, 1.179382111866019]) \n",
      "4600: D: 0.7625303864479065/0.6577083468437195 G: 0.8665573000907898 (Real: [3.9087528562545777, 1.2598086063762175], Fake: [4.1222230744361879, 1.1743785971556191]) \n",
      "4800: D: 0.6452483534812927/0.6937959790229797 G: 0.7753536701202393 (Real: [4.0001033389568326, 1.2145953166845558], Fake: [4.3538873803615568, 1.3273690165837]) \n",
      "5000: D: 0.694851815700531/0.5651698112487793 G: 0.719517171382904 (Real: [4.0020610576868059, 1.2760616506581879], Fake: [3.9885473752021792, 1.3681696890820998]) \n",
      "5200: D: 0.5736491084098816/0.6534281969070435 G: 0.6286905407905579 (Real: [4.097035995721817, 1.3014636891179148], Fake: [3.7797825169563293, 1.1538351372724329]) \n",
      "5400: D: 1.2236530780792236/0.5929282903671265 G: 1.0570580959320068 (Real: [3.8746367716789245, 1.1602090639505245], Fake: [3.7865651905536652, 1.1762967237279318]) \n",
      "5600: D: 0.5464525818824768/0.6950870752334595 G: 0.9060788750648499 (Real: [4.0146834039688111, 1.2643444320896682], Fake: [4.1988970255851745, 1.3157984973668704]) \n",
      "5800: D: 0.630740225315094/0.59291672706604 G: 0.7422086000442505 (Real: [3.8078983330726626, 1.0846323756120568], Fake: [4.0636479878425602, 1.2005626017916733]) \n",
      "6000: D: 0.6315532922744751/0.6738684773445129 G: 0.5037413835525513 (Real: [3.8027128157112746, 1.1146199288716478], Fake: [3.9828707098960878, 1.1324317651063536]) \n",
      "6200: D: 1.0398192405700684/0.8173606991767883 G: 0.8661139011383057 (Real: [4.1180707836151127, 1.0935345203672748], Fake: [4.1548996162414547, 1.2884919279365035]) \n",
      "6400: D: 0.6702655553817749/0.7215916514396667 G: 0.784027636051178 (Real: [3.9435616719722746, 1.2538347564977241], Fake: [3.9581385630369188, 1.3238124660458614]) \n",
      "6600: D: 0.9396241307258606/0.6591554284095764 G: 0.6425179243087769 (Real: [3.9828431703150273, 1.2850565643497702], Fake: [3.7210985225439073, 1.2641940005364702]) \n",
      "6800: D: 0.9376610517501831/0.6624519228935242 G: 0.653540313243866 (Real: [3.8771607130765915, 1.0849594973795149], Fake: [3.9185047817230223, 1.3281153990738881]) \n",
      "7000: D: 0.6347455382347107/0.5549424886703491 G: 0.8355196714401245 (Real: [3.8195369994640349, 1.0986986786765167], Fake: [3.8232599371671676, 1.2560195581006921]) \n",
      "7200: D: 0.9353591799736023/0.8743539452552795 G: 0.9687557220458984 (Real: [4.0298259651660917, 1.397090065758088], Fake: [4.0061151540279392, 1.157908415836558]) \n",
      "7400: D: 0.4291039705276489/0.8487216830253601 G: 0.5229547023773193 (Real: [3.8554038578271865, 1.2446831422932219], Fake: [4.1855887627601627, 1.1833817539399576]) \n",
      "7600: D: 1.102113962173462/0.9622027277946472 G: 0.791329026222229 (Real: [4.0620661735534664, 1.2709582307953307], Fake: [3.8386953020095826, 1.0931613872907011]) \n",
      "7800: D: 0.7738078236579895/0.916973352432251 G: 0.9325355291366577 (Real: [4.1942148303985594, 1.1178125186464962], Fake: [4.2350258624553678, 1.3949918267524926]) \n",
      "8000: D: 0.533781111240387/0.6865549087524414 G: 0.5828307271003723 (Real: [4.1160347878932955, 1.2819397721665344], Fake: [4.0772321629524235, 1.1671525734687289]) \n",
      "8200: D: 0.6529565453529358/0.6143621802330017 G: 0.745597779750824 (Real: [4.2154924690723421, 1.2213831699753184], Fake: [3.881563209295273, 1.1503676250999162]) \n",
      "8400: D: 0.3694423735141754/0.7798583507537842 G: 0.7581692337989807 (Real: [3.983708682656288, 1.4264338011363453], Fake: [4.4663331127166748, 1.20533746593692]) \n",
      "8600: D: 0.6460981369018555/0.49372729659080505 G: 0.6758972406387329 (Real: [3.9788546715676785, 1.2272113978212853], Fake: [4.1318237227201458, 1.1630676509207178]) \n",
      "8800: D: 0.37879520654678345/0.7874966859817505 G: 0.37988752126693726 (Real: [4.1394642060995102, 1.3561933778217286], Fake: [3.4974129405617713, 1.2408691728951526]) \n",
      "9000: D: 0.781507134437561/0.5307419300079346 G: 0.9490299820899963 (Real: [4.0630307686328884, 1.3263662046180047], Fake: [4.213253084421158, 1.1833427038075497]) \n",
      "9200: D: 0.953818678855896/0.4582422971725464 G: 1.0559016466140747 (Real: [4.0020386934280392, 1.0941387288362299], Fake: [4.1990596276521686, 1.0781851330339922]) \n",
      "9400: D: 0.7614408135414124/0.6246402859687805 G: 0.7387111783027649 (Real: [3.9757281398773192, 1.2199890282160502], Fake: [3.9055082714557647, 1.2783518153356672]) \n",
      "9600: D: 0.49027588963508606/0.6069946885108948 G: 0.3769908845424652 (Real: [3.8777377378940581, 1.3052969137510424], Fake: [4.1945915371179581, 1.2688130323630424]) \n",
      "9800: D: 0.6158949732780457/0.5195255279541016 G: 0.945829451084137 (Real: [4.0333191657066347, 1.2105092745088293], Fake: [4.10826605796814, 1.2709401022260809]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: D: 0.9485693573951721/0.8106628656387329 G: 0.7467162609100342 (Real: [3.7736936104297638, 1.172259436712225], Fake: [4.1009891617298129, 1.0948647583559137]) \n",
      "10200: D: 0.5122779011726379/0.5562213063240051 G: 0.6588876843452454 (Real: [4.0858793282508854, 1.3087501835893263], Fake: [3.9643237501382829, 1.2205015387764857]) \n",
      "10400: D: 0.5323874950408936/0.3354381322860718 G: 1.3748964071273804 (Real: [3.9118615794181824, 1.2032777235712033], Fake: [4.3512736088037487, 1.2216805645132136]) \n",
      "10600: D: 0.5690218210220337/0.4919187128543854 G: 0.689799427986145 (Real: [3.9542882061004638, 1.1695150378502559], Fake: [3.9697003972530367, 1.116197163708049]) \n",
      "10800: D: 0.20576399564743042/0.5444735884666443 G: 0.6415402293205261 (Real: [4.0184838759899142, 1.2941799754148864], Fake: [4.0245869338512419, 1.2580973766562631]) \n",
      "11000: D: 0.31965500116348267/1.0085173845291138 G: 0.44921875 (Real: [4.1759560453891753, 1.2899029860735498], Fake: [4.1455021870136264, 1.2485395237450279]) \n",
      "11200: D: 0.8011404871940613/0.5375352501869202 G: 0.5845998525619507 (Real: [4.2889556872844699, 1.1629046069588949], Fake: [3.7547471040487288, 1.3041874628804069]) \n",
      "11400: D: 0.6663974523544312/0.8759945631027222 G: 0.43103012442588806 (Real: [3.9580932706594467, 1.201249217609683], Fake: [4.0652982193231582, 1.2875367869769567]) \n",
      "11600: D: 0.8479769229888916/0.48527514934539795 G: 1.244861125946045 (Real: [3.9428122484683992, 1.3835586966400979], Fake: [3.8575976169109345, 1.3567402866424525]) \n",
      "11800: D: 1.021254539489746/0.24535836279392242 G: 1.5655192136764526 (Real: [4.1428808104991912, 1.1920292653346996], Fake: [4.1907060158252714, 1.160802001188477]) \n",
      "12000: D: 0.6599222421646118/0.5284170508384705 G: 0.6490212678909302 (Real: [3.9362529003620148, 1.1404431878894059], Fake: [4.3113094741106037, 1.2239140293522153]) \n",
      "12200: D: 1.0207030773162842/0.4478168189525604 G: 0.9293017387390137 (Real: [4.0968304777145388, 1.1882209689874277], Fake: [3.8272770762443544, 1.3356427379693818]) \n",
      "12400: D: 0.45664265751838684/0.7637588977813721 G: 1.2870936393737793 (Real: [3.9682132863998412, 1.229345054103711], Fake: [3.8200581336021422, 1.253629421102844]) \n",
      "12600: D: 0.7688742876052856/0.49211573600769043 G: 0.8708677291870117 (Real: [3.9533197683095933, 1.2048104674089044], Fake: [4.3181522768735885, 1.2461138595769745]) \n",
      "12800: D: 0.23667213320732117/0.35323190689086914 G: 0.931911051273346 (Real: [3.9971006262302398, 1.199558862813535], Fake: [3.9697885584831236, 1.3012977215265935]) \n",
      "13000: D: 0.40204763412475586/0.5133188366889954 G: 1.3893519639968872 (Real: [3.8367893451452257, 1.2123091233457299], Fake: [4.1535396087169651, 1.178456364550265]) \n",
      "13200: D: 0.6163399815559387/0.24494537711143494 G: 1.335902214050293 (Real: [4.2921325775980952, 1.2809925400740061], Fake: [3.8082016962766647, 1.3219885415238823]) \n",
      "13400: D: 0.3058732748031616/0.2516423761844635 G: 1.308286428451538 (Real: [4.0565573084354405, 1.161106205811208], Fake: [3.8319874030351637, 1.2106812720559117]) \n",
      "13600: D: 0.0571078285574913/0.7831943035125732 G: 0.7166503667831421 (Real: [3.8261280167102814, 1.1649834757383375], Fake: [3.9564670419692991, 1.2479172677374479]) \n",
      "13800: D: 0.3083980679512024/0.48166972398757935 G: 0.8772947788238525 (Real: [4.1306719100475311, 1.2196652408832855], Fake: [4.1123927950859072, 1.232545354535644]) \n",
      "14000: D: 0.4420696794986725/0.22171421349048615 G: 1.064085841178894 (Real: [4.0201758503913876, 1.3684268168550009], Fake: [3.9381661009788513, 1.2681796666632703]) \n",
      "14200: D: 0.8358575105667114/0.1866476684808731 G: 1.4177956581115723 (Real: [3.912939663529396, 1.1513407577654968], Fake: [3.8353827327489851, 1.31146340160191]) \n",
      "14400: D: 0.7826485633850098/0.9617741107940674 G: 0.6513494253158569 (Real: [3.8437914156913759, 1.24004701486146], Fake: [3.9344504511356355, 1.21966537939177]) \n",
      "14600: D: 0.16786448657512665/0.2708788514137268 G: 2.019688844680786 (Real: [4.1097634863853454, 1.2348563942005359], Fake: [4.1139407277107241, 1.1449828559084227]) \n",
      "14800: D: 0.7078035473823547/0.5883611440658569 G: 3.0309228897094727 (Real: [4.0506969082355502, 1.1997115979203998], Fake: [4.1175568783283234, 1.2296691558540354]) \n",
      "15000: D: 0.7196882963180542/0.19557951390743256 G: 1.671262502670288 (Real: [3.9463899266719817, 1.2373161876886396], Fake: [4.241142817735672, 1.1374300443042809]) \n",
      "15200: D: 0.5871667861938477/0.12751847505569458 G: 1.0238487720489502 (Real: [4.1808065879344944, 1.1353637162560986], Fake: [4.2850774323940275, 1.1735980880861383]) \n",
      "15400: D: 0.6810628175735474/0.252778559923172 G: 1.5626124143600464 (Real: [3.8060009351372717, 1.1123282405599324], Fake: [3.7715059053897857, 1.3720115305314018]) \n",
      "15600: D: 0.23753245174884796/0.739273190498352 G: 1.746325135231018 (Real: [3.8779159629344941, 1.2536275485166117], Fake: [3.6347390794754029, 1.2854264239464084]) \n",
      "15800: D: 1.3692561388015747/0.6725893020629883 G: 0.31635782122612 (Real: [4.2386713540554046, 1.2773076740033389], Fake: [4.1517144322395323, 1.1759532529032291]) \n",
      "16000: D: 0.2549002766609192/0.5490917563438416 G: 0.7011696100234985 (Real: [3.8875469720363616, 1.1262002801352151], Fake: [3.9063915300369261, 1.356992346134549]) \n",
      "16200: D: 0.31713899970054626/0.6032662391662598 G: 1.282442331314087 (Real: [4.2236287903785703, 1.0998954426830543], Fake: [4.0664568591117858, 1.1361956381956284]) \n",
      "16400: D: 0.04310773313045502/1.2212671041488647 G: 2.1801352500915527 (Real: [3.9067056846618651, 1.2778554711524905], Fake: [4.0383031642436977, 1.4166056260283755]) \n",
      "16600: D: 0.05314527451992035/0.0782494992017746 G: 2.983818769454956 (Real: [3.9336338537931441, 1.307350110460801], Fake: [3.8085553157329559, 1.3205834765598041]) \n",
      "16800: D: 0.020958248525857925/0.47703397274017334 G: 0.4908026456832886 (Real: [3.8034867883473633, 1.3306991441215432], Fake: [4.2981225669384004, 1.2193726441172124]) \n",
      "17000: D: 0.27731063961982727/1.2260663509368896 G: 2.050180435180664 (Real: [3.9868512821197508, 1.2189388371922774], Fake: [4.1914894580841064, 1.2317861279497069]) \n",
      "17200: D: 1.2309507131576538/0.05632274970412254 G: 3.068594455718994 (Real: [4.2143419523164631, 1.295940076371612], Fake: [4.1112632507085802, 1.2375312058886043]) \n",
      "17400: D: 1.241050124168396/0.0425136536359787 G: 2.483370542526245 (Real: [4.0100669878721238, 1.1903211127898043], Fake: [4.1404583001136777, 1.1728480287749015]) \n",
      "17600: D: 0.29362398386001587/0.11236143112182617 G: 2.311235189437866 (Real: [4.1521013015508652, 1.2799590062403396], Fake: [3.4337684172391891, 1.2239860188136378]) \n",
      "17800: D: 0.5410966873168945/0.6719788908958435 G: 2.6118268966674805 (Real: [3.9395154249668121, 1.291685099550641], Fake: [3.7500716018676759, 1.4304822432209408]) \n",
      "18000: D: 0.8931806683540344/0.08389121294021606 G: 2.272733688354492 (Real: [4.0610389745235445, 1.0925736034165388], Fake: [4.2201084840297698, 1.2803663050495397]) \n",
      "18200: D: 0.06807571649551392/0.32510828971862793 G: 1.7536917924880981 (Real: [4.221212532520294, 1.2233844979909367], Fake: [4.0198551791906354, 1.3620417664199802]) \n",
      "18400: D: 0.028495997190475464/0.06587871164083481 G: 2.1706721782684326 (Real: [4.0633633878827098, 1.347808440221417], Fake: [3.6713130450248719, 1.4599177868547339]) \n",
      "18600: D: 0.03444482758641243/0.26428189873695374 G: 0.2043268084526062 (Real: [3.8432898855209352, 1.0967200200300224], Fake: [4.0718377876281737, 1.2223881623461867]) \n",
      "18800: D: 0.2440134882926941/0.1110612004995346 G: 0.9103043675422668 (Real: [3.9743949502706526, 1.3441227937896072], Fake: [4.3577653264999388, 1.1349467387628431]) \n",
      "19000: D: 0.7596361637115479/0.12207454442977905 G: 1.1974520683288574 (Real: [4.0191296732425688, 1.1579869252746018], Fake: [4.1953545528650285, 1.1437993010765486]) \n",
      "19200: D: 0.6424890160560608/0.3026975095272064 G: 1.957494854927063 (Real: [4.0076729065179828, 1.2883738085084631], Fake: [3.9719449752569198, 1.2348128283676649]) \n",
      "19400: D: 0.0057525672018527985/0.28739163279533386 G: 1.5183318853378296 (Real: [4.0110806232690814, 1.2937897054667251], Fake: [3.9282802242040633, 1.2383194241825082]) \n",
      "19600: D: 2.06953763961792/0.11847759783267975 G: 3.1694624423980713 (Real: [4.0245007228851319, 1.133117231060299], Fake: [4.1660485869646076, 1.1752792547294602]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19800: D: 0.1778448224067688/0.25703558325767517 G: 1.0865757465362549 (Real: [3.899229212999344, 1.2730725259531681], Fake: [3.7362002617120744, 1.3196759059842063]) \n",
      "20000: D: 0.04035596922039986/1.7935454845428467 G: 2.845966339111328 (Real: [3.8619731092453002, 1.1810351638044498], Fake: [4.1703265231847766, 1.1102070887110032]) \n",
      "20200: D: 0.07320480793714523/0.03559655696153641 G: 1.4348039627075195 (Real: [3.8897855523601175, 1.2898105227760008], Fake: [3.8613371509313583, 1.4116380289757369]) \n",
      "20400: D: 0.07747320830821991/0.2461923211812973 G: 0.20697583258152008 (Real: [4.0408905553817753, 1.2708659522625199], Fake: [4.3441728645563122, 1.145649639806926]) \n",
      "20600: D: 1.7431493997573853/0.2421710342168808 G: 2.1173717975616455 (Real: [4.2202457667887208, 1.2938268300700155], Fake: [4.6763345324993137, 1.0764294393848022]) \n",
      "20800: D: 0.24189963936805725/0.1331222951412201 G: 2.1456825733184814 (Real: [3.9748358857631683, 1.1635641792253912], Fake: [4.4862626981735225, 1.1319964056834855]) \n",
      "21000: D: 0.2979637086391449/0.2317853718996048 G: 1.493196964263916 (Real: [3.9620379716157914, 1.2846188288867983], Fake: [4.0873603498935696, 1.2769716256236652]) \n",
      "21200: D: 0.0009995328728109598/0.485416978597641 G: 2.5290307998657227 (Real: [3.8671200859546659, 1.3142918090094051], Fake: [4.4128362226486209, 1.206427235200648]) \n",
      "21400: D: 0.14530321955680847/0.11387677490711212 G: 1.4833340644836426 (Real: [4.2211575555801391, 1.345017325528401], Fake: [4.4400629442930217, 1.4355899128346363]) \n",
      "21600: D: 0.3713051676750183/0.8620682954788208 G: 0.9114314913749695 (Real: [3.7649469396471975, 1.3074517216816641], Fake: [4.2353043913841244, 1.2753268796467923]) \n",
      "21800: D: 0.17933641374111176/0.31349870562553406 G: 2.055050849914551 (Real: [4.0868440985679628, 1.356501974028042], Fake: [4.3217105025053026, 1.4063381277740945]) \n",
      "22000: D: 0.6176870465278625/0.0696549341082573 G: 2.4538378715515137 (Real: [4.178376487493515, 1.3067174999669484], Fake: [4.2157068026065829, 1.32694738706181]) \n",
      "22200: D: 0.19161871075630188/0.8948086500167847 G: 0.4765964150428772 (Real: [4.0157814705371857, 1.1438592879190055], Fake: [4.3045422029495235, 1.1351994639874534]) \n",
      "22400: D: 0.44027575850486755/0.1874004751443863 G: 1.2773295640945435 (Real: [3.9854700124263762, 1.1316839747487255], Fake: [4.3174434030056004, 1.1919979584435512]) \n",
      "22600: D: 0.20516258478164673/0.704406201839447 G: 0.19700585305690765 (Real: [4.0461270797252658, 1.2035060835913809], Fake: [4.0319446015357974, 1.39749198541265]) \n",
      "22800: D: 0.2675687074661255/0.35503408312797546 G: 0.6745660305023193 (Real: [4.1061353504657747, 1.2338085174637083], Fake: [3.7495786380767822, 1.3303196913907922]) \n",
      "23000: D: 0.5037351846694946/0.41469043493270874 G: 1.4859471321105957 (Real: [4.0524337124824523, 1.2590462708291248], Fake: [4.4192999839782718, 1.3391915252010682]) \n",
      "23200: D: 1.3158742189407349/0.17233818769454956 G: 2.098215341567993 (Real: [4.0261038947105412, 1.2601219104229939], Fake: [4.441981222629547, 1.3694089989950595]) \n",
      "23400: D: 0.46786150336265564/0.830491840839386 G: 0.694345235824585 (Real: [4.150382647514343, 1.162828428145233], Fake: [3.9868152970075608, 1.3443826652576207]) \n",
      "23600: D: 1.4818357229232788/1.0330594778060913 G: 1.7223955392837524 (Real: [4.2723495221138004, 1.05909730021707], Fake: [3.9763321167230608, 1.024772591709447]) \n",
      "23800: D: 0.7023505568504333/0.7674611806869507 G: 0.2584569752216339 (Real: [4.3114393591880802, 1.2081252109460774], Fake: [4.3064159965515136, 1.4348173585438142]) \n",
      "24000: D: 0.2209080308675766/0.17850659787654877 G: 0.6898363828659058 (Real: [4.1455022740364074, 1.2219597468652308], Fake: [4.5664452123641972, 1.203046209634945]) \n",
      "24200: D: 0.05050990730524063/1.8337759971618652 G: 0.0937998816370964 (Real: [4.0207955431938167, 1.2292748169057517], Fake: [4.0276614499092105, 1.0893278633750427]) \n",
      "24400: D: 0.5491085052490234/0.38466179370880127 G: 0.6362055540084839 (Real: [3.9507023209333418, 1.2580792157327525], Fake: [4.0528802406787872, 1.3668760555345862]) \n",
      "24600: D: 0.7595419883728027/1.1549614667892456 G: 0.7734910249710083 (Real: [3.8894465839862824, 1.229674460043878], Fake: [3.7954663801193238, 1.2446427120294565]) \n",
      "24800: D: 0.5919235944747925/1.1378639936447144 G: 1.1591801643371582 (Real: [4.0276479649543759, 1.1827505967680632], Fake: [4.0763045454025271, 1.40491670913485]) \n",
      "25000: D: 0.8237302303314209/0.49256953597068787 G: 0.6945290565490723 (Real: [4.0923709964752195, 1.1679195344882087], Fake: [4.5279091811180114, 1.1031879511037797]) \n",
      "25200: D: 1.0482232570648193/0.48470932245254517 G: 0.7172593474388123 (Real: [4.4663442468643186, 1.1872319292091793], Fake: [4.1930441546440127, 1.444035619341411]) \n",
      "25400: D: 0.9045450687408447/0.4709852933883667 G: 0.7582835555076599 (Real: [4.1076780676841738, 1.1628464566068599], Fake: [3.9716806602478028, 1.3300250993287606]) \n",
      "25600: D: 0.551487922668457/0.7784346342086792 G: 0.531391978263855 (Real: [3.8563551592826841, 1.1975083547673759], Fake: [3.8576021742820741, 1.315795242666272]) \n",
      "25800: D: 0.8168656229972839/0.6578298211097717 G: 0.7301333546638489 (Real: [3.8323324066400528, 1.4223285496004219], Fake: [4.609215776920319, 1.3521546023431981]) \n",
      "26000: D: 0.6426826119422913/0.7868158221244812 G: 0.7004098892211914 (Real: [4.1799747323989864, 1.2367860988023995], Fake: [3.8088840699195861, 1.0697547155737601]) \n",
      "26200: D: 0.8393791913986206/0.6739548444747925 G: 0.7884592413902283 (Real: [3.891860740184784, 1.2410884667717725], Fake: [3.5924710237979891, 1.2157117441164971]) \n",
      "26400: D: 0.8476497530937195/0.6312384605407715 G: 0.79232257604599 (Real: [4.1919992798566819, 1.2250590725460402], Fake: [4.3785941171646119, 1.3085582273135452]) \n",
      "26600: D: 0.8181236386299133/0.9337620139122009 G: 0.6955727338790894 (Real: [3.8556753778457642, 1.2674687843741661], Fake: [3.9144352138042451, 1.1443752720491218]) \n",
      "26800: D: 0.8093031048774719/0.8587261438369751 G: 0.7547113299369812 (Real: [4.0803916311264041, 1.1340618561991711], Fake: [3.7839840090274812, 1.3052930983494631]) \n",
      "27000: D: 0.6971633434295654/0.6378792524337769 G: 0.6999711394309998 (Real: [4.0318599331378939, 1.2293623986415574], Fake: [3.9880742764472963, 1.066342536271536]) \n",
      "27200: D: 0.656676709651947/1.1486785411834717 G: 0.6881071925163269 (Real: [3.685065259486437, 1.0849652274799009], Fake: [3.8448116958141325, 1.3197498516127308]) \n",
      "27400: D: 0.7555800676345825/0.6913189888000488 G: 0.6872779130935669 (Real: [3.9259182024002075, 1.1197834589226348], Fake: [4.3254335737228393, 1.1903568648904808]) \n",
      "27600: D: 0.4825257360935211/0.8969383239746094 G: 0.6744794845581055 (Real: [3.841919283270836, 1.1801665507285208], Fake: [3.9011166310310363, 1.1951818940563022]) \n",
      "27800: D: 0.6472437977790833/0.7728872895240784 G: 0.5785971283912659 (Real: [4.0561677330732344, 1.2737292490217444], Fake: [3.9531741988658906, 1.2607489685723789]) \n",
      "28000: D: 0.708572506904602/0.6956256031990051 G: 0.6945132613182068 (Real: [3.8282638722658158, 1.1830316058110284], Fake: [4.358788044452667, 1.4150611995533722]) \n",
      "28200: D: 0.8913083672523499/0.7080652713775635 G: 0.7049320936203003 (Real: [3.9807255280017855, 1.1911409785400768], Fake: [3.7431320452690127, 1.2802636249590678]) \n",
      "28400: D: 0.7172386646270752/0.6977298259735107 G: 0.7060377597808838 (Real: [4.1336923280358313, 1.3442090419699562], Fake: [4.2156905055046083, 1.2774642840165118]) \n",
      "28600: D: 0.5578152537345886/0.7422236800193787 G: 0.7240248322486877 (Real: [3.843498110026121, 1.4471272152081169], Fake: [3.7287126517295839, 1.215828164822516]) \n",
      "28800: D: 0.7214756011962891/0.737851083278656 G: 0.5575056076049805 (Real: [4.1782737028598786, 1.1625020893134954], Fake: [3.9397002720832823, 1.2118093453060761]) \n",
      "29000: D: 0.8411044478416443/0.5924939513206482 G: 0.5258339643478394 (Real: [4.0702741378545761, 1.4998814842745489], Fake: [4.2066850733757022, 1.2015064082471885]) \n",
      "29200: D: 0.6875827312469482/0.7805407643318176 G: 0.6461892127990723 (Real: [4.0680374994874002, 1.2715903794031771], Fake: [3.6052100682258605, 1.2199902805782818]) \n",
      "29400: D: 0.7211195826530457/0.5423243045806885 G: 0.7092300653457642 (Real: [3.8536993157863617, 1.1727192157078501], Fake: [4.3092257428169249, 1.3198721084016476]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29600: D: 0.8818122148513794/0.8872649073600769 G: 0.7833473086357117 (Real: [3.8258704704046251, 1.1866414491810533], Fake: [4.5922258043289181, 1.200524216590622]) \n",
      "29800: D: 0.7342708706855774/0.8494189977645874 G: 0.5542294383049011 (Real: [4.068523369431496, 1.2442353027278581], Fake: [3.207109948396683, 1.1192780112382186]) \n"
     ]
    }
   ],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n",
    "\n",
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)\n",
    "\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
